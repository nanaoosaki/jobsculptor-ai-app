WEBVTT

1
00:00:31.345 --> 00:00:40.345
A few logistic things. The meeting is being recorded. If you have any questions, feel free to ask them in the chat window. I will summarize and address them one by one after the presentation.


2
00:00:40.345 --> 00:00:47.345
If time permits, we'll also have a live Q&A session. So let's start with a simple question.


3
00:00:47.345 --> 00:00:54.345
Have you ever read through the official docs on MCP, maybe watched a few demos and still walked away thinking?


4
00:00:54.345 --> 00:00:59.345
Oh, this seems important, but I'm not sure how it fits into my work.


5
00:00:59.345 --> 00:01:06.345
Or maybe you've seen people use it too early hit weird bugs and walk away thinking the AI doesn't work.


6
00:01:06.345 --> 00:01:12.345
Where the real issue wasn't the protocol itself. It was using it at the wrong time.


7
00:01:12.345 --> 00:01:17.345
You are not alone. If either of this resonates. That uncertainty doesn't mean you are behind.


8
00:01:17.345 --> 00:01:25.345
It actually means you're asking the right questions. Using a good tool at the wrong time can be worse than not using it at all.


9
00:01:25.345 --> 00:01:33.345
And this lightning course is designed to reframe that experience and rebuild strategic confidence.


10
00:01:33.345 --> 00:01:38.345
Right now, we are living in a moment of protocol overload.


11
00:01:38.345 --> 00:01:50.345
Lynching, OpenAI plugins, claw tools, function calling, AutoGen, OpenAPI, MCP, Have you seen all these tool names? Maybe not at all, but never really understood the differences.


12
00:01:50.345 --> 00:02:03.345
It feels like every major LLM provider or open source group is pushing its own standard for how models should talk to tools. The challenge isn't just a lack of options, but too many.


13
00:02:03.345 --> 00:02:11.345
All with overlapping capabilities, but different assumptions. If you're building agents or integrating OOMs into applications.


14
00:02:11.345 --> 00:02:17.345
The question isn't, can I build this? It's which tool chain shall I commit to?


15
00:02:17.345 --> 00:02:28.345
And what happens when the next particle comes along? So today, we're not just going to explain what MCP is. We're going to explore when it's useful.


16
00:02:28.345 --> 00:02:32.345
What trade-offs it introduces and how to make an informed decision.


17
00:02:32.345 --> 00:02:38.345
Not a reflective one, a reactive one. All right, Siri is great.


18
00:02:38.345 --> 00:02:43.345
But let's make this tangible. To kick things off, I want to show you something concrete.


19
00:02:43.345 --> 00:02:47.345
Imagine a common scenario. We need to build a relatively simple agent.


20
00:02:47.345 --> 00:02:54.345
His job? To interact with the local SQLite database. We're not talking about a massive complex system here.


21
00:02:54.345 --> 00:02:59.345
The core tasks are straightforward. We wanted to be able to list the tables within that database.


22
00:02:59.345 --> 00:03:07.345
Allow us or allow the LLM to inspect the schema of those tables and perhaps even execute a basic SQL query directly.


23
00:03:07.345 --> 00:03:13.345
So let's jump right into the demo. Here, I will use this tool. I also developed it.


24
00:03:13.345 --> 00:03:18.345
To dictate the prompts so that we can save the time typing the potential long prompts into cursor.


25
00:03:18.345 --> 00:03:21.345
We will also use cursor as the tool to build all of this.


26
00:03:21.345 --> 00:03:25.345
And let's click stop to see whether that works or not. Great, it works.


27
00:03:25.345 --> 00:03:36.345
Then let's dictate the prompt. I wanted to build an agent to allow, say, GPT-4-0 to understand or explore local SQLite database.


28
00:03:36.345 --> 00:03:41.345
We already have the database ready with the name of e-commerce underscore data.db.


29
00:03:41.345 --> 00:03:54.345
This file in the current folder And I would like to provide three tools to GPT. The first tool is called List Tables. It would list all the tables in that SQLite database.


30
00:03:54.345 --> 00:04:15.345
In return string. The second is called get schema. It accepts a string parameter of the table name and then return another string describing the table schema, which may contain the the a column name, column type. And in the end, we could also include a


31
00:04:15.345 --> 00:04:19.345
Example, data roll to it so that LOM has more context.


32
00:04:19.345 --> 00:04:32.345
So the return value is also a string. And the third is… The tool is called Executor Circle. It accepts a string of SQL statements as input and outputs the execution result.


33
00:04:32.345 --> 00:04:37.345
Probably in a CSV format. To the ROM.


34
00:04:37.345 --> 00:04:44.345
And we would like to use Lilisk OpenAI SDK to do all of this, use GPT-4-0 as the LLM.


35
00:04:44.345 --> 00:04:54.345
And the task we ask LM to do is explore this database and provide a markdown report describing the basic facts of the table. For example.


36
00:04:54.345 --> 00:05:10.345
The data schemas of each table. All right, click stop here. So we will get all of it speech recognized copied here check for any potential misspelling or speech recognition error.


37
00:05:10.345 --> 00:05:20.345
Nope. So we'll just submit it. Here, I'm using cursor together with the Gemini 2.5, which I found pretty effective in doing software engineering work.


38
00:05:20.345 --> 00:05:27.345
And it understand the task. It come up with a plan.


39
00:05:27.345 --> 00:05:33.345
And even knows to update the cursor rules on this specific plan will accept it here.


40
00:05:33.345 --> 00:05:45.345
It has a pretty clear goal build an agent to enable GPT-4-0 to explore a local SQLite database. And it divided into five steps.


41
00:05:45.345 --> 00:05:49.345
Setup and planning. Tool implementation.


42
00:05:49.345 --> 00:06:00.345
It already looks like it goes a detour, create a dummy database which is not necessary So we will correct it here, stopped execution and ask it.


43
00:06:00.345 --> 00:06:07.345
Actually, you don't need to create a dummy database. We already have an existing database called e-commerce underscore data.db.


44
00:06:07.345 --> 00:06:12.345
All right. Copy. Paste, enter.


45
00:06:12.345 --> 00:06:20.345
Hopefully this will correct this route. Accept.


46
00:06:20.345 --> 00:06:29.345
And then it will implement the tools and perform an open ai integration.


47
00:06:29.345 --> 00:06:39.345
And then do the main script and reporting generation ensure GBD-4 ensure products and markdown markdown report And testing on refinement looks pretty professional.


48
00:06:39.345 --> 00:06:44.345
So move on to implementing the Python function. This is the framework.


49
00:06:44.345 --> 00:07:03.345
Of the Python function it implements as list tables only this one and now it's this one probably will implement other functions one by one This is a tendency of Gemini, which knows to decompose a complicated task into stages so that it has


50
00:07:03.345 --> 00:07:09.345
Better success rate in terms of implementation as well as calling cursor to do the editing.


51
00:07:09.345 --> 00:07:18.345
And the final tool of execute a SQL. At this time, we can also take a closer look at how it implements all of this.


52
00:07:18.345 --> 00:07:25.345
List tables essentially just run a SQL query on the meta database of the SQLite.


53
00:07:25.345 --> 00:07:31.345
The gas schema or so get this. Use this.


54
00:07:31.345 --> 00:07:38.345
Pragma statement. And execute a SQL.


55
00:07:38.345 --> 00:07:47.345
All right it knows to test it in the middle of development, which is good So that we could discover any bugs before we go into production.


56
00:07:47.345 --> 00:07:55.345
And then it adjusted the examples steal a syntax error.


57
00:07:55.345 --> 00:08:04.345
And seems to be working as intended for this syntax error looks like it's intentional because it knows it is invalid.


58
00:08:04.345 --> 00:08:14.345
And then it will install the OpenAI library. It's super fun to watch AI doing all of this work for us.


59
00:08:14.345 --> 00:08:27.345
Get a pretty comprehensive plan update its progress stage by stage write hundreds of lines of code in no time manage the dependencies smartly.


60
00:08:27.345 --> 00:08:40.345
And it decides to split the implementation of the Sucrolite agent here with the general TB tool so that we could reuse the functions in the future. That's also a smart move.


61
00:08:40.345 --> 00:08:46.345
And here's the key. This is how we will describe to the OpenAI API.


62
00:08:46.345 --> 00:08:51.345
What tools are available to GPT-4. Essentially, they are in the form of functions.


63
00:08:51.345 --> 00:09:00.345
Which is called towards the anthropic world, but it's called functions in opening ai world It describes the name out function the power meters and the return value.


64
00:09:00.345 --> 00:09:07.345
The description is also provided to tell the AI when you need to use that and what it is for.


65
00:09:07.345 --> 00:09:25.345
So essentially, you can see that we use a specific JSON schema to describe our intent, our provided tools to the gpt4o And then so that the AI knows when to invoke which tool and in which format.


66
00:09:25.345 --> 00:09:48.345
So what happened is it caused this Python script. The Python script or the api the GPT-4-0 first receives this prompt, which is written by cursor. Essentially, it asks it to do some initial exploration using the tools against this database.


67
00:09:48.345 --> 00:09:54.345
And the first turn, the GPT-4-0 with the sites Let's invoke list tables too.


68
00:09:54.345 --> 00:10:00.345
With zero arguments, which is expected, and got the results of channels, customer types.


69
00:10:00.345 --> 00:10:07.345
Daily metrics, et cetera, which is exactly the tables in this SQLite database.


70
00:10:07.345 --> 00:10:13.345
And then it knows to invoke tools of gas schema.


71
00:10:13.345 --> 00:10:19.345
With table name of channels and get this result and invoke other.


72
00:10:19.345 --> 00:10:25.345
For other tables using this same tool one by one. And collect all this information.


73
00:10:25.345 --> 00:10:33.345
After it gets all this information. It knows to produce a final response, which is a markdown result.


74
00:10:33.345 --> 00:10:37.345
Of the table. Of description of the table.


75
00:10:37.345 --> 00:10:46.345
So that concludes this entire task, it is able to generate such a markdown.


76
00:10:46.345 --> 00:10:54.345
I want to point out that This markdown looks trivial. It's nothing more than just doing some exploration of the table.


77
00:10:54.345 --> 00:11:02.345
Imagine if you could automate it if you could ask it to generate an insightful, deep analysis on the example data.


78
00:11:02.345 --> 00:11:11.345
Which is totally possible. Then how much easier it will make your work like your work will be much easier.


79
00:11:11.345 --> 00:11:23.345
So then this actually gives us a pretty good foundation that it shows that it shows how to build an agent capable of querying local database.


80
00:11:23.345 --> 00:11:31.345
And that agent in its interaction with the database tools followed exactly this core invocation flow we see here.


81
00:11:31.345 --> 00:11:49.345
The lm in our cases, open AI model decided to use a tool like list tables or guest schema And then formulated and sent a structured tool called which our client code executed against the SQLite database. And this client code is


82
00:11:49.345 --> 00:12:00.345
Implemented as a Python code in our implementation. And that is that result, it queries against the circle i database and get result.


83
00:12:00.345 --> 00:12:05.345
That result, like the table names, schema information, were returned to the LLM.


84
00:12:05.345 --> 00:12:12.345
And then OM will do another round of decision making, which tool I need to call or shall I stop here and begin generating the final report?


85
00:12:12.345 --> 00:12:24.345
And this is the fundamental cycle of agentic tool use. It's important to recognize that for this kind of straightforward single tool interaction or single IOM interaction.


86
00:12:24.345 --> 00:12:28.345
You likely didn't need to implement a comprehensive or overarching framework.


87
00:12:28.345 --> 00:12:35.345
You probably didn't even need to bring something like the modern context protocol or MCP that we'll be discussing more.


88
00:12:35.345 --> 00:12:45.345
For this basic scenario, the native function calling capabilities provided by your LLM were likely sufficient to get the job done effectively.


89
00:12:45.345 --> 00:12:52.345
But then comes the inevitable next step. After considering simple


90
00:12:52.345 --> 00:13:04.345
I'll just unmute. All right. And then here is a consider another perspective that may be inevitable.


91
00:13:04.345 --> 00:13:10.345
After considering the simple single model scenarios. Perhaps you want to experiment with a different model.


92
00:13:10.345 --> 00:13:20.345
Like Anthropic Claude or maybe a client has a specific requirement on Google's gemini Or you're interested in exploring another open source alternative.


93
00:13:20.345 --> 00:13:35.345
So suddenly you take that perfectly good tool you developed for one model And try to use it with another And you hit a wall. It's not just that it doesn't work out of the box. Often, the entire way the tool is defined and expected to interact


94
00:13:35.345 --> 00:13:50.345
Simply doesn't fit the new model's paradigm. So the core of the issue is that the different models from different providers often employ their own unique schemas for defining tools. They can have varied calling conventions for how those tools are invoked.


95
00:13:50.345 --> 00:13:59.345
And how arguments are passed? Furthermore, their error handling patterns and the way expected results to be returned can also differ significantly.


96
00:13:59.345 --> 00:14:03.345
What was once a straightforward call of function in one ecosystem.


97
00:14:03.345 --> 00:14:10.345
Can quickly devolve into a tedious process of rewriting and rewrapping this tool for every single platform I want to support.


98
00:14:10.345 --> 00:14:16.345
And that is the real friction point we often encounter in agentic AI development.


99
00:14:16.345 --> 00:14:22.345
This frustrating lack of portability for our tools and capabilities across different models.


100
00:14:22.345 --> 00:14:29.345
It's a significant hurdle to building truly flexible and future-proof AI applications.


101
00:14:29.345 --> 00:14:36.345
Indeed, when we want to scale our agent or switch to a different model provider, perhaps Claude.


102
00:14:36.345 --> 00:14:40.345
Or another open source alternative, that simple agent we built often starts to fork.


103
00:14:40.345 --> 00:14:50.345
The cream of tour abuse quickly fades. And art development surface area multiplies increasing complexity and mintness.


104
00:14:50.345 --> 00:15:00.345
This is the common pinpoint that MCP tries to address. The model context protocol, or MCP, was designed to tackle this very challenge.


105
00:15:00.345 --> 00:15:15.345
And his heart. The protocol was meticulously designed to establish consistent and standardized interface between AI models the clients that interacted with them And the various tools and resources these models might need to use.


106
00:15:15.345 --> 00:15:24.345
It's crucial to understand that MCP isn't another heavyweight framework you need to learn. Instead, think of it as a lightweight wire format.


107
00:15:24.345 --> 00:15:30.345
An effective abstraction layer. And a clear contract that governs those interactions.


108
00:15:30.345 --> 00:15:33.345
The diagram you see on the slide is a great visual metaphor.


109
00:15:33.345 --> 00:15:43.345
Mcb acts as a central hub A standard that allows many different tools and various AI models to connect and communicate seamlessly.


110
00:15:43.345 --> 00:15:50.345
The real power of MCP lies in its ability to make your tool definitions, your carefully crafted prompt templates.


111
00:15:50.345 --> 00:15:55.345
And even your references to external resources truly model agnostic.


112
00:15:55.345 --> 00:16:00.345
The philosophy is simple but profound. Define these components once.


113
00:16:00.345 --> 00:16:04.345
And they reuse them everywhere across different AI models and platforms.


114
00:16:04.345 --> 00:16:18.345
And this directly supports the core goal we mentioned earlier. To foster and enable a rich interoperable ecosystem where tools can be developed independently and used broadly.


115
00:16:18.345 --> 00:16:23.345
And MCP is gaining serious traction. Cloud Desktop supports it out of the box.


116
00:16:23.345 --> 00:16:35.345
Cursor has built-in integration. Openai is rolling it out google has signal to support. And as Orbit is the originator, but the adoption curve now spans the entire LM ecosystem.


117
00:16:35.345 --> 00:16:41.345
This isn't just the one company's vision. It's being adopted across multiple LLM providers and tooling platforms.


118
00:16:41.345 --> 00:16:51.345
Mcp is not French. But remember, just because it's supported or because it's popular doesn't mean you must use it now.


119
00:16:51.345 --> 00:16:58.345
So you might be wondering, if MCP is so powerful. Why is this still controversial?


120
00:16:58.345 --> 00:17:06.345
Let me show you. We will take the same Sucralite agent we discussed, and this time we'll expose it via a fast MCP server.


121
00:17:06.345 --> 00:17:14.345
Fastmcp is a community SDK that helps implement the protocol. Then we'll call it from cursor and from Cloud Desktop.


122
00:17:14.345 --> 00:17:20.345
Same tool implementation, different clients. This would highlight the right ones use anywhere idea.


123
00:17:20.345 --> 00:17:32.345
And this is a real scenario. Many teams want model agnostic tool development So I'll come back here and begin from this dbtools probably the silicide agent.


124
00:17:32.345 --> 00:17:40.345
We will just tell the ai Now I'll take another look at the Sukolite agent We wanted to convert it into MCP server.


125
00:17:40.345 --> 00:17:46.345
We want to use the fast MCP as the SDK. And probably you need to search online on how to use that.


126
00:17:46.345 --> 00:17:58.345
In this process, let's make sure are of the paths mentioned in the file is absolute path.


127
00:17:58.345 --> 00:18:14.345
And then paste it here. Probably we also need to give it our count root. I'll just copy paste it here.


128
00:18:14.345 --> 00:18:25.345
I begin generating. Let's take a look at the crystal rules. Probably, it's already updated And then Gemini begins to plan several faces.


129
00:18:25.345 --> 00:18:41.345
Update the current progress and the plan.


130
00:18:41.345 --> 00:18:59.345
The goal of this project. I guess the project is the project we're using here. The overall goal of this project is to enable the AI to explore a database, a SQLite database specifically on its own so that we don't need to tell it, hey, this is the table, that is the structure


131
00:18:59.345 --> 00:19:08.345
The AI would know to use different tools to actually autonomously discover all the details.


132
00:19:08.345 --> 00:19:17.345
This is the goal. All right. And then we have the DB tools revised here.


133
00:19:17.345 --> 00:19:26.345
And deleting. Actually, I don't really want to delete this will rejected.


134
00:19:26.345 --> 00:19:37.345
And we have… Where is our code, MCB server are still to be created So I'll accept the changes here.


135
00:19:37.345 --> 00:19:41.345
Take a look at the cursor rules to see where we are.


136
00:19:41.345 --> 00:19:47.345
Still implementing the MCP server.


137
00:19:47.345 --> 00:20:01.345
Directly reuse the existing database tools which makes it Pretty clear.


138
00:20:01.345 --> 00:20:07.345
And note that how we ask it to do online search to understand how to use fast MPC.


139
00:20:07.345 --> 00:20:11.345
Actually, if we don't include that, it will try to hallucinate.


140
00:20:11.345 --> 00:20:31.345
Because it has no knowledge about this pretty new library. However, in a case that it learns online, it knows a how to write a code and B, how to actually launch this debunking proxy. So let's take a look at this port.


141
00:20:31.345 --> 00:20:42.345
Follow the link here and click connect. This will connect to our MCP server, our newly authored MCP server. And just to give an overview of what the code looks like.


142
00:20:42.345 --> 00:20:49.345
It basically is pretty simple. Three functions The key here is you just decorate it with mcp.tool.


143
00:20:49.345 --> 00:20:54.345
That's it. After that, we'll be able to go to the inspector. This is called MCP inspector.


144
00:20:54.345 --> 00:21:07.345
It's some tool coming with MCP. Sdk, and then we can go to tools list the tools, then we'll be able to see the three tools available, the tools exposed to AI.


145
00:21:07.345 --> 00:21:14.345
And if we click into each tool, it will give us more information. Like this tool is to list all the tables in SQLite database.


146
00:21:14.345 --> 00:21:19.345
And in this case, we can directly click wrong tool. It will be able to just run the tool.


147
00:21:19.345 --> 00:21:23.345
And give us the result. So now we just have an MCP server.


148
00:21:23.345 --> 00:21:30.345
And we also expect to see it really works using the common debugging tool. It's that easy.


149
00:21:30.345 --> 00:21:38.345
But how can we connect it with the clients? Here we have the clients. One example is cursor. I will also show Claw Desktop.


150
00:21:38.345 --> 00:21:41.345
So what we'll do here is ask to do online search again.


151
00:21:41.345 --> 00:21:46.345
Now I'd like to connect this MCP server with Cursor. Could you please do some online search?


152
00:21:46.345 --> 00:22:07.345
We need to be applied to the AI. And then potentially generate a dot cursor slash mcp.json to allow me to use this MCP server encryption.


153
00:22:07.345 --> 00:22:15.345
We need to be polite. Remove this this shouldn't be one part of the prompt.


154
00:22:15.345 --> 00:22:26.345
And let's see how to connect it. With cursor. And you can see here one pattern is how extensively i delegate the the task to AI. Actually, I don't need to know.


155
00:22:26.345 --> 00:22:29.345
I don't need to remember how to connect it to cursor.


156
00:22:29.345 --> 00:22:40.345
Ai could just do the search for me. This is like the mindset of delegating the task to AI to maximize your brainpower.


157
00:22:40.345 --> 00:22:49.345
It's like you have a team doing all the low level work for you and you can really focus on the real creative things that require your expertise.


158
00:22:49.345 --> 00:22:55.345
All right. So it did its research And we can generate this file.


159
00:22:55.345 --> 00:23:01.345
Okay, it generated this file i'll just Accepted.


160
00:23:01.345 --> 00:23:20.345
And then we can go to this icon go to mcp icon And we can find this tool, this MCP server available we also see this pop-up window here. We can enable here or enable here. Both will work. Let's just enable it.


161
00:23:20.345 --> 00:23:29.345
And it says client closed. Then that means we need to do some debugging.


162
00:23:29.345 --> 00:23:37.345
In most of the cases, that's just the means we just means we probably would have some issue in the Python execution.


163
00:23:37.345 --> 00:23:44.345
Because we already checked. This MCB server worked. So I'll tell cursor to do that.


164
00:23:44.345 --> 00:23:59.345
Instead of first use the sh to activate the virtual environment Could you please just use the full path of the python as the executable.


165
00:23:59.345 --> 00:24:13.345
And let's see whether we could correct it.


166
00:24:13.345 --> 00:24:18.345
All right. We will accept. And refresh.


167
00:24:18.345 --> 00:24:28.345
And re-enable. Now the error is gone. It works now. So then we'll see how can we use that in cursor.


168
00:24:28.345 --> 00:24:42.345
Now, we'll just ask it use the MCP server of Sukalite Database Explorer and list the tables in the database.


169
00:24:42.345 --> 00:24:55.345
And note that we're using Gemini. We'll see whether it works.


170
00:24:55.345 --> 00:25:01.345
It works. It caused the MCP of list all tables and get the result.


171
00:25:01.345 --> 00:25:10.345
Great. How about how great we do the same thing but switch it to GPT.


172
00:25:10.345 --> 00:25:20.345
Same thing. Get this. What about Claude? And here, I don't want to show it in cursor here we will show it from even another client.


173
00:25:20.345 --> 00:25:27.345
The clot has a Claude desktop. I'll just create a new one.


174
00:25:27.345 --> 00:25:40.345
The tricky part here is cloud desktop needs to configure the config MCPS server as well. And how do we config is we need two.


175
00:25:40.345 --> 00:25:45.345
I'll just remove everything and begin from scratch. We need to add a configuration file.


176
00:25:45.345 --> 00:25:56.345
How to access that is we go to settings. There's a developer. And in the developer, there's a config we could click The added config, it will show the config file in the folder in the finder.


177
00:25:56.345 --> 00:26:03.345
And then we'll just open it here. Notice that currently, because I don't have any MCP server.


178
00:26:03.345 --> 00:26:12.345
This is an empty. And what I'll do is just a copy paste to this configuration file from cursor to Claude. That's it.


179
00:26:12.345 --> 00:26:20.345
Then we just restart the cloud desktop app So it could reload.


180
00:26:20.345 --> 00:26:30.345
This. All right. Here, if we click here search and tools, we'll be able to see there is a SQLite DB Explorer already available.


181
00:26:30.345 --> 00:26:34.345
This is good. That means it's connected with our MCP server.


182
00:26:34.345 --> 00:26:38.345
Then we can further ask it. Just copy this again.


183
00:26:38.345 --> 00:26:44.345
Ask it. Use MCB server or SQL data base explorer list the tables in the database.


184
00:26:44.345 --> 00:27:01.345
And here I want to challenge it a little bit. Can you do some more comprehensive exploration on the exploration on on the data and come up with some data on deep data analysis with even visualizations.


185
00:27:01.345 --> 00:27:11.345
And I'll just allow it here. This warning is to say that i The clause needs to cause some external resources, which is the MCP server here.


186
00:27:11.345 --> 00:27:16.345
To prevent security risk it will need the user.


187
00:27:16.345 --> 00:27:29.345
To confirm. And here I would just ask you to do more exploration. So it diligently spans quite a few different different requests to our database.


188
00:27:29.345 --> 00:27:32.345
And try to crunch the numbers and come up with something.


189
00:27:32.345 --> 00:27:38.345
So we'll leave it running here. And come back to our original.


190
00:27:38.345 --> 00:27:42.345
Presentation. All right, I'll close it.


191
00:27:42.345 --> 00:27:48.345
What's this here?


192
00:27:48.345 --> 00:27:58.345
So following on our demo. Let's assume we can see that actually everything initially works beautifully. We had some small bug, but quickly fix that.


193
00:27:58.345 --> 00:28:00.345
But I also want to show you the other side of MCP.


194
00:28:00.345 --> 00:28:06.345
So essentially what happened was we have the tool implementation.


195
00:28:06.345 --> 00:28:14.345
And we make it accessible through FastMCP. And then we showed it successfully called by different clients like cursor and Cloud desktop.


196
00:28:14.345 --> 00:28:24.345
It perfectly illustrates the core promise of MCC. Genuinely interoperability and the ability to write tools once and use them across various platforms.


197
00:28:24.345 --> 00:28:43.345
That's a powerful concept to realize. But then, as is often the case in development, we will intentionally introduce a subtle bug. It doesn't have to be a major architecture flaw. It's just probably a small oversight. For instance, we probably will give it a incorrect file pass.


198
00:28:43.345 --> 00:28:49.345
For the SQLite database or a tiny typo So let's see that.


199
00:28:49.345 --> 00:28:56.345
So it sounds like the clot is still pleasing busy proposing the report.


200
00:28:56.345 --> 00:29:03.345
And at this time, I'll just… Close.


201
00:29:03.345 --> 00:29:07.345
This is the fast MCP server. Let's terminate that because it's for debugging only.


202
00:29:07.345 --> 00:29:18.345
And go to the mcp.json. Let's give it some typo. Before that, it seems that the clot or the finisher's job.


203
00:29:18.345 --> 00:29:30.345
Wrote quite a few SQL queries. Run it against the database and come up with this nice analytics dashboard showing the core metrics from this database.


204
00:29:30.345 --> 00:29:40.345
Which is very nice. And imagine that in your work, what if you could just do your weekly business review based on this draft rather than having everything from scratch?


205
00:29:40.345 --> 00:29:50.345
How many hours this could save you. All right. Coming back to this debugging issue, let's intentionally make it not work.


206
00:29:50.345 --> 00:29:57.345
Instead of using absolute paths. Because I know it will fail if we don't use that. Let's use this.


207
00:29:57.345 --> 00:30:03.345
Argument, make it relative past. What will happen? In cursor.


208
00:30:03.345 --> 00:30:11.345
If we go to MCP, probably turn it off refresh, turn on it says client closed. Okay.


209
00:30:11.345 --> 00:30:15.345
Client closed, what does that mean? How would I debug?


210
00:30:15.345 --> 00:30:25.345
And get error messages and fix my code. Because of that. If we click here, it knows it will show we need to go to output and cursor MCP for error locks.


211
00:30:25.345 --> 00:30:33.345
Okay, we go to here output go to cursor mcp it says error plan closed.


212
00:30:33.345 --> 00:30:37.345
Okay, what does that mean? I don't know. And there's a reason for that.


213
00:30:37.345 --> 00:30:59.345
It's not because MCP is not because badly implemented that it exposed a little information for debugging. It's just because MCP is a client-server architecture. And this architecture means that they don't know the across this boundary. And this makes this debugging extremely hard.


214
00:30:59.345 --> 00:31:06.345
And if we just recover this, still use the absolute pass, come back.


215
00:31:06.345 --> 00:31:18.345
Refresh? Turn on it works again. But what if we go to the MCP server and change this absolute.


216
00:31:18.345 --> 00:31:24.345
Let's see, it should be tools change this absolute path to relative paths.


217
00:31:24.345 --> 00:31:29.345
So for example, we just For the DB name is this.


218
00:31:29.345 --> 00:31:41.345
So here is the tricky part. If we go to here, still mcp refresh this wheel still be successful.


219
00:31:41.345 --> 00:31:45.345
However, if we redo this query.


220
00:31:45.345 --> 00:31:52.345
Let's see what will happen. It says Suclide error, unable to open database file.


221
00:31:52.345 --> 00:31:56.345
But in the case that you check this path, it's still correct.


222
00:31:56.345 --> 00:32:04.345
A skier is still correct. E-commerce data.db is correct. And even in the case that You want to use fast MCP.


223
00:32:04.345 --> 00:32:10.345
To debug it. Because you're launching this from the current folder.


224
00:32:10.345 --> 00:32:18.345
It will still tell you these tools list tools, list all tables wrong tool it will still tell you the correct result.


225
00:32:18.345 --> 00:32:25.345
So now we enter a really tricky part. That our debugging tool says nothing's wrong.


226
00:32:25.345 --> 00:32:30.345
It runs beautifully. And our client says, no, I can't open the database file.


227
00:32:30.345 --> 00:32:39.345
So I just want to show that even some really small errors, even not complicated mistakes is very hard to debug.


228
00:32:39.345 --> 00:32:45.345
Unless you know a lot especially the details about MCP.


229
00:32:45.345 --> 00:32:55.345
So I'll just remove all this and recover so it won't break things.


230
00:32:55.345 --> 00:33:02.345
So I want to say that The reason behind it is because you're no longer debunking Python.


231
00:33:02.345 --> 00:33:12.345
You're debugging the JSON RPC, the over HTTP between distributed components And with unclear logs, as this diagram shows.


232
00:33:12.345 --> 00:33:21.345
And those client-server model schema boundaries becomes harder to trace. And this is the first, the hidden cost of MCP.


233
00:33:21.345 --> 00:33:27.345
Debugging gets harder. The abstraction that gives you portability also removes immediate feedback.


234
00:33:27.345 --> 00:33:33.345
You don't see the wiring anymore. You see the endpoints and hope the wiring works.


235
00:33:33.345 --> 00:33:37.345
You're not debugging functions, but semantic boundaries. This isn't a design flaw.


236
00:33:37.345 --> 00:33:48.345
But a trade-off. Abstract protocols reduce visibility. And MCVA's purpose is to scale and standardize, not necessarily to make things easier during early experimentation.


237
00:33:48.345 --> 00:33:56.345
So what are your options? Well, let's take a third approach. Let's rebuild that circleite agent using just a prompt and a command line.


238
00:33:56.345 --> 00:34:00.345
No server, no protocol, just a tool and a natural language description.


239
00:34:00.345 --> 00:34:06.345
And this introduces the linked approach. Here, I'll just ask.


240
00:34:06.345 --> 00:34:12.345
Take a look at the db uh the the mcp server and SQLite agent.puyi.


241
00:34:12.345 --> 00:34:25.345
We want to make it a command line utility. For example, you would accept a switch about which mode or which command to execute with some optional commands.


242
00:34:25.345 --> 00:34:43.345
And let's first write a new Python script. Of doing the command line parsing and also write a document in Markdown so that future AI will know how to use this tool.


243
00:34:43.345 --> 00:34:48.345
Here, I'll use the dimension.


244
00:34:48.345 --> 00:34:54.345
Mcp server.py and GP should be super light.


245
00:34:54.345 --> 00:35:01.345
Poi. All right.


246
00:35:01.345 --> 00:35:06.345
And the goal of this is cursor itself is an agent.


247
00:35:06.345 --> 00:35:15.345
In those holding work tools. And because it knows how to execute a command line utility like a shell command.


248
00:35:15.345 --> 00:35:20.345
We could just build a command. Or Camilla utility for it.


249
00:35:20.345 --> 00:35:27.345
To invoke. That's it. And this is the real direct and quick.


250
00:35:27.345 --> 00:35:32.345
Way to Just to do some agentic exploration.


251
00:35:32.345 --> 00:35:41.345
And here, because we're using GPT 4.1, it's just much faster than the the Gemini.


252
00:35:41.345 --> 00:35:50.345
And it also gives us a readme So then what we'll do is we'll just have this readme file and send a cursor.


253
00:35:50.345 --> 00:36:09.345
Following instructions in this readme. Use the command line tool to explore the sucralite database Especially, let's start from how like the table names, listing the table names


254
00:36:09.345 --> 00:36:19.345
And we're using QBD 4.1 here. Okay, great. It knows to invoke this with list tables as the command line And get the table names. That's it.


255
00:36:19.345 --> 00:36:28.345
It's that simple. And notice how more robust And quick, to compare it with MCP. So we do have some other options here.


256
00:36:28.345 --> 00:36:32.345
Due to the limit of time, we'll skip another demo on open web UI.


257
00:36:32.345 --> 00:36:40.345
But we will also mention that briefly. So I also want to emphasize it has cost as well.


258
00:36:40.345 --> 00:36:51.345
It's pretty straightforward, but it lacks structures. There's no schema and no interface contract prompt errors becomes model misinterpretations.


259
00:36:51.345 --> 00:36:55.345
You will hit soft failures and have to guess what went wrong.


260
00:36:55.345 --> 00:37:22.345
The speed of those prompt-based tools is a double-edged sword. All right. We have explored a few different approaches to enable our AI models to interact with tools and external systems to print altogether, let's look at this summary table, which compares three distinct paths we've touched upon. It's important to understand the nuances of each before making a decision for your own specific project.


261
00:37:22.345 --> 00:37:28.345
And first, we have what we call the function calling capabilities.


262
00:37:28.345 --> 00:37:37.345
It typically refers to using the native function calling provided by specific OM vendors like OpenAI's offering. As we saw, this approach is generally simple to implement.


263
00:37:37.345 --> 00:37:48.345
And it can be quite effective for straightforward use cases. However, its main limitation is that it often ties you to that vendor specific API and ecosystem.


264
00:37:48.345 --> 00:37:53.345
And second, there's the MCP-based implementation. Leveraging the model context protocol.


265
00:37:53.345 --> 00:38:00.345
This path offers significant power and crucially. Portability across different models and platforms.


266
00:38:00.345 --> 00:38:08.345
This standardization MCP brings a huge advantage for long-term flexibility and tool usability.


267
00:38:08.345 --> 00:38:15.345
But the trade-off, as we have discussed, can be an increase in complexity, particularly when it comes to debugging interactions.


268
00:38:15.345 --> 00:38:24.345
As there is an added layer of abstraction. And third, we consider a prompt plus CLI hybrid.


269
00:38:24.345 --> 00:38:31.345
This method, where you might instruct a model, generate a command line interface commands, can be very fast for initial interaction.


270
00:38:31.345 --> 00:38:47.345
And prototyping. You can get something up and running quickly. But the challenges here, however, lies in the standardization and ensuring robust, error-proof interactions, especially as the complexity of the tasks grow.


271
00:38:47.345 --> 00:38:57.345
It's critical to recognize that each of these approaches is valid and has a specific role to play during depending on the context.


272
00:38:57.345 --> 00:39:02.345
This comparison, as the table you see, isn't about crowning a single winner or loser.


273
00:39:02.345 --> 00:39:09.345
It's about understanding their relative strengths, weaknesses, positioning, and the inherent trade-offs.


274
00:39:09.345 --> 00:39:20.345
For example, a project like Open Web UI makes extensive use of OpenAPI. Note that it's not OpenAI's API. It's called OpenAPI. It's an existing standard for APIs.


275
00:39:20.345 --> 00:39:26.345
And that's a perfectly sensible choice, given the requirements for broad web service integration.


276
00:39:26.345 --> 00:39:30.345
And there simply isn't a one size fits all best protocol.


277
00:39:30.345 --> 00:39:36.345
So this naturally leads to the critical question. Given these options and their trade-offs.


278
00:39:36.345 --> 00:39:39.345
How do you actually choose the right path for your needs?


279
00:39:39.345 --> 00:39:44.345
Here's the framework we have used and found effective. Ask yourself three questions.


280
00:39:44.345 --> 00:39:52.345
Are you targeting multiple LLMs or deployment environments? Do you need standardized tools across team or platforms?


281
00:39:52.345 --> 00:39:57.345
Is your product already in a stable or scaling phase, not in a rapid prototyping mode?


282
00:39:57.345 --> 00:40:02.345
And these questions separate early stage builders from production stage architects.


283
00:40:02.345 --> 00:40:06.345
If all three are yes, MCP is probably a smart bet.


284
00:40:06.345 --> 00:40:11.345
If even one is no, you might be better off sticking to something lighter.


285
00:40:11.345 --> 00:40:20.345
For now. Remember, the cost of misusing MCP often isn't rewriting code later, it's wasting confidence now.


286
00:40:20.345 --> 00:40:25.345
And that's the key point. Mcp isn't a bad attack. It's just often misused.


287
00:40:25.345 --> 00:40:37.345
Looking at this typical product lifecycle. Exploration prototyping, MVP, and production Things like simple prompt plus COI are great for early stages.


288
00:40:37.345 --> 00:40:46.345
Fast duration, low overload And MCP designed for robustness and reused fits better as you move towards MVP and production.


289
00:40:46.345 --> 00:40:53.345
Where standardization and cross-platform support become more critical. Mcp isn't a beginner's tool.


290
00:40:53.345 --> 00:41:02.345
It's a development abstract. It's a deployment abstraction. Is for systems that are ready to scale, not for projects still exploring use cases.


291
00:41:02.345 --> 00:41:12.345
And that really brings us to the core skill. The crucial takeaway I want to spotlight, as we discuss these different approaches to building and deploying AI agents.


292
00:41:12.345 --> 00:41:18.345
It's a nuanced point, but an incredibly important one. For anyone working this rapidly growing field.


293
00:41:18.345 --> 00:41:27.345
The critical skill here isn't necessarily about the technical ability to write an MCP server from scratch or implement the most complex protocol.


294
00:41:27.345 --> 00:41:33.345
As foundational models become more powerful and tooling improves. The basic mechanics of building agents.


295
00:41:33.345 --> 00:41:40.345
Getting them to perform tasks is in many ways becoming more accessible and easier over time.


296
00:41:40.345 --> 00:41:46.345
Instead, the real expertise, the true mark of an experienced builder or architect.


297
00:41:46.345 --> 00:41:57.345
Lies in the judgment, the ability to discern when a particular abstraction like MCP is the right choice for a specific project, your team, and your current stage of development.


298
00:41:57.345 --> 00:42:06.345
Knowing when to introduce layers of abstraction. Went to standardize interfaces for broader use and when to maintain simplicity for rapid iteration.


299
00:42:06.345 --> 00:42:11.345
That's the difficult part. That's a strategic judgment we need to cultivate.


300
00:42:11.345 --> 00:42:20.345
And the famous saying by Donna Knuth, often paraphrased on the slide, reminds us premature optimization is the root of much evil in programming.


301
00:42:20.345 --> 00:42:28.345
Choosing a powerful but complex protocol like MCP too early can indeed be a form of premature optimization.


302
00:42:28.345 --> 00:42:38.345
Leading to unnecessary overhead and slowed progress on agility is needed. And that's the builder's mindset.


303
00:42:38.345 --> 00:42:43.345
It has three layers as shown here. First, you understand why things exist.


304
00:42:43.345 --> 00:42:50.345
Ecosystem, the incentives the history You decode trends and ask deeper questions.


305
00:42:50.345 --> 00:42:57.345
Second, you build hands-on. Not just reading blocks, but shipping tools, debugging pipelines, working through ambiguity.


306
00:42:57.345 --> 00:43:04.345
Prototyping rapidly. Third, you develop an opinion. Your own filter for hype versus insight.


307
00:43:04.345 --> 00:43:11.345
You develop a point of view and stay independent. This is what we teach in our full AI Builders course.


308
00:43:11.345 --> 00:43:16.345
You're not just learning tools, you're learning how to build judgment and skill.


309
00:43:16.345 --> 00:43:19.345
You will get practice making trade-offs, not just reading about them.


310
00:43:19.345 --> 00:43:25.345
You will work with real tools under uncertainty in structured projects.


311
00:43:25.345 --> 00:43:42.345
You will leave just not knowing more, but thinking better. And it works. Our students have come from Meta, Google, OpenAI, GP Morgan, and obtain your labs. Some engineers, other product managers, data scientists, even professors.


312
00:43:42.345 --> 00:43:46.345
Note the diverse backgrounds of those learners. They all found their own paths.


313
00:43:46.345 --> 00:43:51.345
Many say the same thing echoed in this testimonial from Max.


314
00:43:51.345 --> 00:43:58.345
This changed how I think. This is great to signal the course is not just about technical tips. It's about longevity in the AI era.


315
00:43:58.345 --> 00:44:06.345
By learning how to learn and how to unlearn. In the last few slides, we'll share a few more of those words, not impress, but invite.


316
00:44:06.345 --> 00:44:13.345
You can read more reviews on the course page. Let's look at another perspective on this transformation.


317
00:44:13.345 --> 00:44:24.345
This comes from TT and the poly scientist at Microsoft. And really underscores how developing a builder's mindset can shift AI from being just an occasional tool to an ingrained daily habit.


318
00:44:24.345 --> 00:44:33.345
Fundamentally changing how one approaches and solves problems. Td shares in a quote The greatest takeaway for me was the mindset shift.


319
00:44:33.345 --> 00:44:40.345
I used to think many tasks were beyond AI's reach. Now, think about how to use AI has become a habit.


320
00:44:40.345 --> 00:44:50.345
It's boosted my productivity both at work and in life. This MySer ship didn't just help me understand AI better, it changed the way I think about solving problems.


321
00:44:50.345 --> 00:44:58.345
And I will say this is a powerful illustration of moving beyond just understanding AI to truly integrating it into our problem-solving DNA.


322
00:44:58.345 --> 00:45:03.345
Arco in sharing these experiences is not similar to impress you with past success.


323
00:45:03.345 --> 00:45:12.345
But rather to extend an invitation for you to consider and potentially experience a similar impactful shift in your own work and thinking.


324
00:45:12.345 --> 00:45:19.345
Continuing with the theme of tangible impact, the next example comes from Christine, a quant researcher at JPMorgan Chase.


325
00:45:19.345 --> 00:45:25.345
Beautifully illustrates a very practical outcome of internalizing these AI building principles.


326
00:45:25.345 --> 00:45:35.345
It's about that powerful transition from merely understanding AI conceptually to actively building tools that integrate into and genuinely enhance one-day workflow.


327
00:45:35.345 --> 00:45:46.345
Ultimately redefining how work itself gets done. Christine shares and will call her experience. This course opened my imagination about what I could use Gen AI for.


328
00:45:46.345 --> 00:45:53.345
I built an application that I now use daily. Something that I never thought I could have created easily.


329
00:45:53.345 --> 00:45:58.345
It helped me think more deeply about what to focus on and what I can delegate to AI.


330
00:45:58.345 --> 00:46:02.345
It's not just about productivity. It's about redefining how I work.


331
00:46:02.345 --> 00:46:10.345
This highlights the journey from possibility to practical application. Creating tools that solve real personal or professional problems.


332
00:46:10.345 --> 00:46:21.345
And again, our intention in sharing this story is to inspire you to consider how you might build tools that address your own unique challenges and opportunities.


333
00:46:21.345 --> 00:46:25.345
It's also crucial to highlight accessibility of those concepts and tools.


334
00:46:25.345 --> 00:46:31.345
And the next review from Ken, a senior product specialist from Thermal Fisher Scientific.


335
00:46:31.345 --> 00:46:40.345
Really speaks to this point. It underscores that you don't need to be a seasoned social engineer with years of coding experience to start leveraging AI effectively.


336
00:46:40.345 --> 00:46:49.345
Even with what might be considered basic Python skills or you're working a role or company not traditionally focused on software development, the builder's mindset.


337
00:46:49.345 --> 00:46:56.345
And the practical tools we explore can be incredibly applicable and empowering.


338
00:46:56.345 --> 00:47:01.345
If today's lesson gives you even one new way to think about protocol.


339
00:47:01.345 --> 00:47:13.345
Imagine what we could build together over a few weeks. So here's our next step. If you want to join cohort of builders learning to navigate the real terrain of applied AI.


340
00:47:13.345 --> 00:47:18.345
Not just tools, but trade-offs, as we have discussed. If you have read the docs and still feel stuck.


341
00:47:18.345 --> 00:47:21.345
Or you are building but unsure if you're on the right track.


342
00:47:21.345 --> 00:47:25.345
If you want to learn how to think, not just copy code.


343
00:47:25.345 --> 00:47:31.345
And discuss architecture and design, not just the syntax. Then come join us.


344
00:47:31.345 --> 00:47:37.345
Thank you all for joining today's session. I hope this gives you a clear understanding of what MCP is.


345
00:47:37.345 --> 00:47:42.345
And what it isn't. You've seen the core capabilities of MCP. You've seen the pain points.


346
00:47:42.345 --> 00:47:48.345
But more importantly, you've seen what happens when a powerful tool is used at a wrong stage.


347
00:47:48.345 --> 00:47:52.345
That's the real story here. Many teams try MCP too early.


348
00:47:52.345 --> 00:47:56.345
When it doesn't work smoothly, they don't just give up on MCP.


349
00:47:56.345 --> 00:48:05.345
They give up on AI altogether. You walk away thinking the tech isn't ready, when really they just needed better timing or a more honest framework for thinking.


350
00:48:05.345 --> 00:48:14.345
That's why we created the full course, not just to show you tools, but to train your timing, your judgment, your builder's mindset.


351
00:48:14.345 --> 00:48:17.345
If that resonates with you, if you want to build it differently and more decisively.


352
00:48:17.345 --> 00:48:27.345
I'd love to see you in the full course. You can scan the QR code on the right and use the code MCP for a discount of $150.


353
00:48:27.345 --> 00:48:36.345
And I will leave you with this final thought. Misusing the right tool at the wrong time can cost more than not using it at all.


354
00:48:36.345 --> 00:48:42.345
All right, I will distribute the recording database file, slide doc, and other relevant resources after this meeting.


355
00:48:42.345 --> 00:48:49.345
Download links will also be sent through email. Thank you. And I will take questions here.


356
00:48:49.345 --> 00:49:05.345
Data scientists. Once the recorder will be posted, I'll post the link through the the email we publish here And could you share a thought about the newly announced agent-to-agent protocol by Google?


357
00:49:05.345 --> 00:49:12.345
To it. I don't really have too much comment on that.


358
00:49:12.345 --> 00:49:28.345
Currently, I… had some exploration on the multi-agent on the multi-agent um route, but haven't really reached that complexity stage of needing a specific protocol for that.


359
00:49:28.345 --> 00:49:35.345
I think overall it's good, but the timing for that release is still uncertain.


360
00:49:35.345 --> 00:49:46.345
I'm not super sure how valuable it is yet because personally, I adopt a slightly different approach that is based on shared documentation, as you can also see here.


361
00:49:46.345 --> 00:50:02.345
We ask in our cursor rules Because the rules will specifically ask the AI to write documents here. And this will make them reusable across different agents while filtering out the too much details.


362
00:50:02.345 --> 00:50:10.345
All right, looks like There are no further questions.


363
00:50:10.345 --> 00:50:22.345
I'll stay here for like 30 more seconds In the case that someone has any more questions, feel free to post it in the chat.


364
00:50:22.345 --> 00:50:32.345
Or unmute directly to discuss.


365
00:50:32.345 --> 00:50:38.345
And thank you for all the nice comments.


366
00:50:38.345 --> 00:50:50.345
If there are no further Patients will adjust the end here and send out the final resources after Probably later today or tomorrow.


367
00:50:50.345 --> 00:50:57.345
And thank you so much for attending. This learning course and asking great questions.


368
00:50:57.345 --> 00:51:01.345
We'll see you again. Thank you. Bye.



